{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c41a91f-0a48-4467-9f5f-4c67a03cc05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><triplet> Punta Cana <subj> La Altagracia Province <obj> located in the administrative territorial entity <subj> Dominican Republic <obj> country <triplet> Higuey <subj> La Altagracia Province <obj> located in the administrative territorial entity <subj> Dominican Republic <obj> country <triplet> La Altagracia Province <subj> Dominican Republic <obj> country <triplet> Dominican Republic <subj> La Altagracia Province <obj> contains administrative territorial entity</s>\n",
      "[{'head': 'Punta Cana', 'type': 'located in the administrative territorial entity', 'tail': 'La Altagracia Province'}, {'head': 'Punta Cana', 'type': 'country', 'tail': 'Dominican Republic'}, {'head': 'Higuey', 'type': 'located in the administrative territorial entity', 'tail': 'La Altagracia Province'}, {'head': 'Higuey', 'type': 'country', 'tail': 'Dominican Republic'}, {'head': 'La Altagracia Province', 'type': 'country', 'tail': 'Dominican Republic'}, {'head': 'Dominican Republic', 'type': 'contains administrative territorial entity', 'tail': 'La Altagracia Province'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "triplet_extractor = pipeline('text2text-generation', model='Babelscape/rebel-large', tokenizer='Babelscape/rebel-large')\n",
    "# We need to use the tokenizer manually since we need special tokens.\n",
    "extracted_text = triplet_extractor.tokenizer.batch_decode([triplet_extractor(\"Punta Cana is a resort town in the municipality of Higuey, in La Altagracia Province, the eastern most province of the Dominican Republic\", return_tensors=True, return_text=False)[0][\"generated_token_ids\"]])\n",
    "\n",
    "print(extracted_text[0])\n",
    "# Function to parse the generated text and extract the triplets\n",
    "def extract_triplets(text):\n",
    "    triplets = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(),'tail': object_.strip()})\n",
    "    return triplets\n",
    "extracted_triplets = extract_triplets(extracted_text[0])\n",
    "print(extracted_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a8d36c-339a-4942-b217-9dc2a2ff08ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, grouped_entities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69b28f7-cfba-4995-a597-3bd239c537d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13064\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(\"data/dracula.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "paragraphs = re.split(r'[\\n]{2,}', text)\n",
    "len(paragraphs)\n",
    "\n",
    "lines = []\n",
    "for p in paragraphs:\n",
    "    lines.extend(re.split(r'[\\n]{1,}', p))\n",
    "\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2b95d8-8b17-429e-ab56-fcff5b9296d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 0 lines\n",
      "Processed: 1000 lines\n",
      "Processed: 2000 lines\n",
      "Processed: 3000 lines\n",
      "Processed: 4000 lines\n",
      "Processed: 5000 lines\n",
      "Processed: 6000 lines\n",
      "Processed: 7000 lines\n",
      "Processed: 8000 lines\n",
      "Processed: 9000 lines\n",
      "Processed: 10000 lines\n",
      "Processed: 11000 lines\n",
      "Processed: 12000 lines\n",
      "Processed: 13000 lines\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = {}\n",
    "for i, line in enumerate(lines):\n",
    "    if (i % 1000 == 0):\n",
    "        print(f\"Processed: {i} lines\")\n",
    "    \n",
    "    results = nlp(line)\n",
    "    for result in results:\n",
    "        word = line[result[\"start\"]:result[\"end\"]]\n",
    "        entity_group = result[\"entity_group\"]\n",
    "        score = result[\"score\"]\n",
    "        \n",
    "        if entity_group == \"PER\":\n",
    "            dummy = {}\n",
    "            dummy.setdefault(\"score\", 0)\n",
    "            dummy.setdefault(\"count\", 0)\n",
    "            \n",
    "            entities.setdefault(word, dummy)\n",
    "            entry = entities[word]\n",
    "            \n",
    "            if score > entry[\"score\"]:\n",
    "                entry[\"score\"] = round(score, 3)\n",
    "                entry[\"type\"] = entity_group\n",
    "                entry[\"count\"] += 1\n",
    "    \n",
    "                entities[word] = entry\n",
    "\n",
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05832e06-5dc6-4b52-b965-f1ce4b645803",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'describe_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdescribe_dict\u001b[49m(entities)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'describe_dict' is not defined"
     ]
    }
   ],
   "source": [
    "describe_dict(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc43892f-d15d-4f3e-9edd-2ebd1fb57053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "MIN_LEN = 1\n",
    "MIN_SCORE = 0.995\n",
    "MIN_COUNT = 2\n",
    "\n",
    "def describe_dict(d, n = 5):\n",
    "    keys = []\n",
    "    for i in range(0, n):\n",
    "        keys.append(random.choice(list(d.keys())))\n",
    "\n",
    "    desc = dict([(k, d[k]) for k in keys])\n",
    "    return desc\n",
    "\n",
    "def entity_filter(pair):\n",
    "    key, value = pair\n",
    "\n",
    "    return (\n",
    "        len(key) > MIN_LEN and \n",
    "        value[\"score\"] >= MIN_SCORE and \n",
    "        value[\"count\"] > MIN_COUNT\n",
    "    )\n",
    "\n",
    "def filter_entities(entities):\n",
    "    return dict(filter(entity_filter, entities.items()))\n",
    "\n",
    "filtered_entities = filter_entities(entities)\n",
    "describe_dict(filtered_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8f7d20-ee00-4109-af18-556e302ce47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b57a0-c5aa-4fe5-8c08-c9b2bb223b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entities_to_graph(entities):\n",
    "    nodes = [(k, v) for (k,v) in entities.items()]\n",
    "    edges = []\n",
    "\n",
    "    node_labels = {f\"{k}\": f\"{k}\" for k in entities}\n",
    "    edge_labels = {}\n",
    "\n",
    "    return (\n",
    "        nodes,\n",
    "        edges,\n",
    "        node_labels,\n",
    "        edge_labels\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d02b36-4d79-4f49-82a1-2ed0374d7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_graph(nodes, edges, node_labels=None, edge_labels=None, title=\"Graph Visualization\"):\n",
    "    \"\"\"\n",
    "    Visualize a graph using NetworkX and Matplotlib.\n",
    "    \n",
    "    Parameters:\n",
    "    nodes: list of nodes\n",
    "    edges: list of tuples representing edges (source, target)\n",
    "    node_labels: dict of node labels (optional)\n",
    "    edge_labels: dict of edge labels (optional)\n",
    "    title: string for graph title\n",
    "    \"\"\"\n",
    "    # Create a new graph\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    G.add_nodes_from(nodes)\n",
    "    # G.add_edges_from(edges)\n",
    "    \n",
    "    # Create a figure with a reasonable size\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    \n",
    "    # Set the layout for the graph\n",
    "    pos = nx.spring_layout(G, k=1, iterations=50)\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw_networkx_nodes(G, pos, alpha=0.7)\n",
    "    nx.draw_networkx_edges(G, pos, edge_color='gray', \n",
    "                          width=1, alpha=0.5)\n",
    "    \n",
    "    # Add node labels if provided\n",
    "    if node_labels is None:\n",
    "        node_labels = {node: str(node) for node in nodes}\n",
    "    nx.draw_networkx_labels(G, pos, node_labels)\n",
    "    \n",
    "    # Add edge labels if provided\n",
    "    if edge_labels is not None:\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
    "    \n",
    "    # Add title and remove axes\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "(nodes, edges, node_labels, edge_labels) = entities_to_graph(filtered_entities)\n",
    "visualize_graph(nodes, edges, node_labels, edge_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
